{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FC Networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM01fFV0Q5k6ZbdahUWCqsR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narendra974/insidedeeplearning/blob/main/FC_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fully Connected Networks\n",
        "\n",
        "To implement any kind of neural network in PyTorch we must phrase the problem as an optimization problem (function minimization)\n",
        "\n",
        "1. Input Data and labels are feed into the process.\n",
        "2. Output of the model is used with the true label to compute a loss.\n",
        "3. quantifying how bad the model is doing with the loss function.\n",
        "4. Compute the gradient of loss with each parameter. \n",
        "5. Update the parameters with the gradients calculated.\n",
        "\n"
      ],
      "metadata": {
        "id": "UueO1ltINFve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function Minimization Problem\n",
        "\n",
        "Alterthe parameters 'Theta' to minimize the error/lossof the neural network's prediction against the correct predictions over the entire dataset."
      ],
      "metadata": {
        "id": "Cg78AD2rQz2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter Learning Rule(Gradient Descent)\n",
        "\n",
        "The new parameters Theta(k+1) are equal to the old parameters minus the gradient with respect to the old parameters of the error/loss of the neural networks prediction against the correct predictions averaged over the entire dataset and down-weighted by the learning rate."
      ],
      "metadata": {
        "id": "ONOC6aqyQ-zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e7Rr0Kj6R4ZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}