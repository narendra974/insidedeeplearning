{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorchBasics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMX/1Uf4XV3BCI3yzX15l96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narendra974/insidedeeplearning/blob/main/PyTorchBasics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This* NoteBook illustrates the examples given in chapter 1 of Inside Deep Learning Book."
      ],
      "metadata": {
        "id": "BRBsVLETE7B1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm.autonotebook import tqdm\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2Xop14FBFLzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any value of n for an n-dimensional array is still a tensor. The word tensor is simply referring to the overall concept of an n-dimenional array.\n",
        "We care about the shape of the tensor as we use different shapes to represent different types of data."
      ],
      "metadata": {
        "id": "7zfiCwB-mkk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch_scalar = torch.tensor(3.14)\n",
        "torch_vector = torch.tensor([1, 2, 3, 4])\n",
        "torch_matrix = torch.tensor([[1, 2, 3, 4],\n",
        "                             [5, 6, 7, 8],\n",
        "                             [9, 10, 11, 12] \n",
        "                            ])\n",
        "torch_tensor3d = torch.tensor([ \n",
        "                               [[1, 2, 3, 4],\n",
        "                                [5, 6, 7, 8],\n",
        "                                [9, 10, 11, 12] \n",
        "                               ],\n",
        "                               [[13, 14, 15, 16],\n",
        "                                [17, 18, 19, 20],\n",
        "                                [21, 22, 23, 24] \n",
        "                               ]\n",
        "                              ])\n",
        "\n",
        "print(torch_scalar.shape)\n",
        "print(torch_vector.shape)\n",
        "print(torch_matrix.shape)\n",
        "print(torch_tensor3d.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6l2RAcdnDPb",
        "outputId": "998939ab-34e1-4ca7-bb55-58c362bd06b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([])\n",
            "torch.Size([4])\n",
            "torch.Size([3, 4])\n",
            "torch.Size([2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converion of data from numpy to Tensor, Viceversa \n",
        "Numpy defaults to 64 bit. Pytorch defaults to 32-bit floats.\n",
        "But when we create 'PyTorch Tensor' from 'Numpy Array' - Tensor will use same data type as Numpy Array \n",
        "\n"
      ],
      "metadata": {
        "id": "VwISgYkOt6Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_np = np.random.random((4, 4))\n",
        "print(x_np)"
      ],
      "metadata": {
        "id": "pZJHBoGQsWKp",
        "outputId": "34a57ade-a651-45a4-d7fb-24ca7a37d8f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.66627752 0.34470361 0.98000092 0.87802965]\n",
            " [0.49663691 0.0667962  0.92238922 0.89889232]\n",
            " [0.97110054 0.76772839 0.18380094 0.48625014]\n",
            " [0.37506643 0.31309093 0.91349204 0.76906552]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_pt = torch.tensor(x_np)\n",
        "print(x_pt)"
      ],
      "metadata": {
        "id": "8nPuq5zfueaH",
        "outputId": "c6bcc40c-99a8-42e4-dd87-007ef88b94c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6663, 0.3447, 0.9800, 0.8780],\n",
            "        [0.4966, 0.0668, 0.9224, 0.8989],\n",
            "        [0.9711, 0.7677, 0.1838, 0.4863],\n",
            "        [0.3751, 0.3131, 0.9135, 0.7691]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid issues with the types, you can always specify the data type to be used 'dtype' with the APIS."
      ],
      "metadata": {
        "id": "-4jVpZCW1PGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_np.dtype, x_pt.dtype)\n",
        "x_np = np.asarray(x_pt, dtype=np.float32)\n",
        "x_pt = torch.tensor(x_np, dtype=torch.float32)\n",
        "print(x_np.dtype, x_pt.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNiogn4H1bwS",
        "outputId": "10e75e82-4e7a-4b07-a4b9-630d1dfe7c2f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64 torch.float64\n",
            "float32 torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logical Operations & Similarity of the APIs between Numpy and Tensor."
      ],
      "metadata": {
        "id": "AtSt_bfG3T9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b_np = (x_np > 0.5)\n",
        "b_pt = (x_pt > 0.5)\n",
        "print(b_np)\n",
        "print(b_np.dtype)\n",
        "print(b_pt)\n",
        "print(b_pt.dtype)"
      ],
      "metadata": {
        "id": "r78p96QA4KmZ",
        "outputId": "1ed7d525-824f-43ad-e58b-f486ed27ecf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ True False  True  True]\n",
            " [False False  True  True]\n",
            " [ True  True False False]\n",
            " [False False  True  True]]\n",
            "bool\n",
            "tensor([[ True, False,  True,  True],\n",
            "        [False, False,  True,  True],\n",
            "        [ True,  True, False, False],\n",
            "        [False, False,  True,  True]])\n",
            "torch.bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not always API are similar, one such example is transose which is explained as below. Please check always documention about API's functionality."
      ],
      "metadata": {
        "id": "F5eFK_Vs5Bsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.transpose(x_np)"
      ],
      "metadata": {
        "id": "5JsLO1VZ5Zki",
        "outputId": "993ff2e8-b5f3-4670-e2bb-71e0563d7553",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6662775 , 0.4966369 , 0.97110057, 0.37506643],\n",
              "       [0.3447036 , 0.0667962 , 0.7677284 , 0.31309092],\n",
              "       [0.9800009 , 0.9223892 , 0.18380095, 0.913492  ],\n",
              "       [0.87802964, 0.89889234, 0.48625013, 0.7690655 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.transpose(x_pt, 0, 1)"
      ],
      "metadata": {
        "id": "e75EEi3H6u5g",
        "outputId": "79e7020f-3db8-40c8-a44b-c1b10b2625bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6663, 0.4966, 0.9711, 0.3751],\n",
              "        [0.3447, 0.0668, 0.7677, 0.3131],\n",
              "        [0.9800, 0.9224, 0.1838, 0.9135],\n",
              "        [0.8780, 0.8989, 0.4863, 0.7691]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First important functionality of PyTorch(Tensor) beyond what numpy can provide is to use GPU to accelarate mathematical caluclations. \n",
        "Below shows some timings related to CPU and Calculations."
      ],
      "metadata": {
        "id": "mUflmMnh7CNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "x = torch.rand(2**11, 2**11)\n",
        "time_cpu  = timeit.timeit(\"x@x\", globals=globals(), number=100)"
      ],
      "metadata": {
        "id": "Wt83yFyl8IqS"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}